{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a3cd99-609f-4273-a6fa-500d7d3f7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5308efe-81b1-4ceb-a5f9-90b50e610512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "emails_data = pd.read_csv(\"hyperparameter.csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46d0577b-cc73-496a-8eba-60fd69963c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc571e29-e72e-49c3-ac98-ea75030229b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>Email 5168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>Email 5169</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>Email 5170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>Email 5171</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>Email 5172</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  \\\n",
       "5167  Email 5168    2   2    2    3    0   0   32    0    0  ...         0   \n",
       "5168  Email 5169   35  27   11    2    6   5  151    4    3  ...         0   \n",
       "5169  Email 5170    0   0    1    1    0   0   11    0    0  ...         0   \n",
       "5170  Email 5171    2   7    1    0    2   1   28    2    0  ...         0   \n",
       "5171  Email 5172   22  24    5    1    6   5  148    8    2  ...         0   \n",
       "\n",
       "      jay  valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
       "5167    0       0    0               0         0         0   0    0   \n",
       "5168    0       0    0               0         0         0   1    0   \n",
       "5169    0       0    0               0         0         0   0    0   \n",
       "5170    0       0    0               0         0         0   1    0   \n",
       "5171    0       0    0               0         0         0   0    0   \n",
       "\n",
       "      Prediction  \n",
       "5167           0  \n",
       "5168           0  \n",
       "5169           1  \n",
       "5170           1  \n",
       "5171           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8078d027-db8c-4369-8b51-914c800c3d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email No.', 'the', 'to', 'ect', 'and', 'for', 'of', 'a', 'you', 'hou',\n",
       "       ...\n",
       "       'connevey', 'jay', 'valued', 'lay', 'infrastructure', 'military',\n",
       "       'allowing', 'ff', 'dry', 'Prediction'],\n",
       "      dtype='object', length=3002)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c956ee5-2978-481c-889f-757813789e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5172, 3002)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7233d00-8531-40f6-84ba-012aa341f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing (TF-IDF vectorization for text data)\n",
    "X = emails_data['text']  # Features (email content)\n",
    "y = emails_data['category']  # Labels (spam/ham or categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0899a14a-bfc4-46b8-9538-467401babc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15d9c5de-7daf-424e-b0dd-19395df7de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a pipeline for text classification\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  # Text data vectorization\n",
    "    ('clf', RandomForestClassifier())  # Initial classifier (Random Forest)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ccd0ba2-7e2d-4a92-8546-45625efe3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Hyperparameter Tuning using Grid Search\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.9, 0.95, 1.0],  # TF-IDF hyperparameters (max document frequency)\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Unigram and Bigram\n",
    "    'clf__n_estimators': [100, 200],  # Number of trees in Random Forest\n",
    "    'clf__max_depth': [10, 20, None]  # Maximum depth of trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d60fc8ef-123b-4c98-9ca0-8ca72ee07992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ignoring all type of warnings\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de4071b2-21e4-4c82-8310-2b41a4693663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all entries in X_train are strings\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b77fafe-08ec-4bfb-acc1-0f4b8c356976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 108 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n108 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2133, in fit_transform\n    X = super().fit_transform(raw_documents)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1388, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1294, in _count_vocab\n    raise ValueError(\nValueError: empty vocabulary; perhaps the documents only contain stop words\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply Grid Search with 3-fold cross-validation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 108 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n108 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2133, in fit_transform\n    X = super().fit_transform(raw_documents)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1388, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Mani\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1294, in _count_vocab\n    raise ValueError(\nValueError: empty vocabulary; perhaps the documents only contain stop words\n"
     ]
    }
   ],
   "source": [
    "# Apply Grid Search with 3-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "import pandas as pd  # Importing pandas for data manipulation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV  # Importing necessary functions for splitting and tuning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Importing TF-IDF vectorizer for text processing\n",
    "from sklearn.ensemble import RandomForestClassifier  # Importing Random Forest classifier\n",
    "from sklearn.pipeline import Pipeline  # Importing Pipeline for creating a model workflow\n",
    "from sklearn.metrics import classification_report  # Importing classification report for evaluation\n",
    "\n",
    "# Load dataset\n",
    "file_path = '/mnt/data/hyperparameter.csv'  # Path to the dataset\n",
    "emails_data = pd.read_csv(file_path)  # Reading the dataset into a pandas DataFrame\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Check if the necessary columns exist\n",
    "if 'text' not in emails_data.columns or 'category' not in emails_data.columns:\n",
    "    raise ValueError(\"The dataset must contain 'text' and 'category' columns.\")\n",
    "\n",
    "# Convert the text column to string to avoid type errors\n",
    "emails_data['text'] = emails_data['text'].astype(str)\n",
    "\n",
    "# Check for null values\n",
    "if emails_data['text'].isnull().any() or emails_data['category'].isnull().any():\n",
    "    raise ValueError(\"The dataset contains null values. Please clean the data before proceeding.\")\n",
    "\n",
    "# Remove empty or whitespace-only entries\n",
    "emails_data = emails_data[emails_data['text'].str.strip() != '']\n",
    "\n",
    "# Ensure there is valid data to process\n",
    "if emails_data.empty:\n",
    "    raise ValueError(\"The dataset contains no valid documents after cleaning.\")\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "print(emails_data.head())\n",
    "\n",
    "X = emails_data['text']  # Features (email content)\n",
    "y = emails_data['category']  # Labels (spam/ham or categories)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80-20 split\n",
    "\n",
    "# Step 2: Define a pipeline for text classification\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', min_df=1)),  # Step for text vectorization\n",
    "    ('clf', RandomForestClassifier(random_state=42))  # Step for classification using Random Forest\n",
    "])\n",
    "\n",
    "# Step 3: Hyperparameter Tuning using Grid Search\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.9, 0.95, 1.0],  # TF-IDF hyperparameters\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Testing unigrams and bigrams\n",
    "    'clf__n_estimators': [100, 200],  # Number of trees in Random Forest\n",
    "    'clf__max_depth': [10, 20, None]  # Max depth of trees\n",
    "}\n",
    "\n",
    "# Apply Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=2)  # Setting up grid search\n",
    "grid_search.fit(X_train, y_train)  # Fitting the grid search model\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters from Grid Search:\")\n",
    "print(grid_search.best_params_)  # Display the best parameters found\n",
    "\n",
    "# Step 4: Hyperparameter Tuning using Random Search\n",
    "param_dist = {\n",
    "    'tfidf__max_df': [0.8, 0.85, 0.9, 1.0],  # Range of values for TF-IDF\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Unigrams and bigrams\n",
    "    'clf__n_estimators': [50, 100, 200, 300],  # Number of trees\n",
    "    'clf__max_depth': [10, 20, 30, None],  # Max depth of trees\n",
    "    'clf__min_samples_split': [2, 5, 10]  # Minimum samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Apply Random Search\n",
    "random_search = RandomizedSearchCV(pipeline, param_dist, n_iter=10, cv=3, n_jobs=-1, verbose=2, random_state=42)  # Setting up random search\n",
    "random_search.fit(X_train, y_train)  # Fitting the random search model\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters from Random Search:\")\n",
    "print(random_search.best_params_)  # Display the best parameters found from random search\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "# Evaluate Grid Search Model\n",
    "y_pred_grid = grid_search.predict(X_test)  # Predictions from the grid search model\n",
    "print(\"Classification Report for Grid Search Tuned Model:\")\n",
    "print(classification_report(y_test, y_pred_grid))  # Display the classification report\n",
    "\n",
    "# Evaluate Random Search Model\n",
    "y_pred_random = random_search.predict(X_test)  # Predictions from the random search model\n",
    "print(\"Classification Report for Random Search Tuned Model:\")\n",
    "print(classification_report(y_test, y_pred_random))  # Display the classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce4a35-7eb4-4632-8587-5f7530a44f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Hyperparameter Tuning using Grid Search\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.9, 0.95, 1.0],  # TF-IDF hyperparameters\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Testing unigrams and bigrams\n",
    "    'clf__n_estimators': [100, 200],  # Number of trees in Random Forest\n",
    "    'clf__max_depth': [10, 20, None]  # Max depth of trees\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f141ce-2f7d-4d72-a9ef-5786416a37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=2)  # Setting up grid search\n",
    "grid_search.fit(X_train, y_train)  # Fitting the grid search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ba418-e0cd-42b2-b844-f10696792697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters\n",
    "print(\"Best Parameters from Grid Search:\")\n",
    "print(grid_search.best_params_)  # Display the best parameters found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed62eb-8279-4bc5-824e-0afaa0a9eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Random Search\n",
    "random_search = RandomizedSearchCV(pipeline, param_dist, n_iter=10, cv=3, n_jobs=-1, verbose=2, random_state=42)  # Setting up random search\n",
    "random_search.fit(X_train, y_train)  # Fitting the random search model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b30da-d7e7-4e2f-a64c-c0fd68032bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Hyperparameter Tuning using Random Search\n",
    "param_dist = {\n",
    "    'tfidf__max_df': [0.8, 0.85, 0.9, 1.0],  # Range of values for TF-IDF\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Unigrams and bigrams\n",
    "    'clf__n_estimators': [50, 100, 200, 300],  # Number of trees\n",
    "    'clf__max_depth': [10, 20, 30, None],  # Max depth of trees\n",
    "    'clf__min_samples_split': [2, 5, 10]  # Minimum samples required to split an internal node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab562716-ebbc-456e-9af8-eb0e0345a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters\n",
    "print(\"Best Parameters from Random Search:\")\n",
    "print(random_search.best_params_)  # Display the best parameters found from random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9cfe0f-d4ab-4041-bd89-d17b6cb0f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Evaluation\n",
    "# Evaluate Grid Search Model\n",
    "y_pred_grid = grid_search.predict(X_test)  # Predictions from the grid search model\n",
    "print(\"Classification Report for Grid Search Tuned Model:\")\n",
    "print(classification_report(y_test, y_pred_grid))  # Display the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab1d61-4205-4316-824e-7bcf0b7744a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Search Model\n",
    "y_pred_random = random_search.predict(X_test)  # Predictions from the random search model\n",
    "print(\"Classification Report for Random Search Tuned Model:\")\n",
    "print(classification_report(y_test, y_pred_random))  # Display the classification report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
